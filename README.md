# ğŸ“„ RAG Document Assistant (Local & OpenAI)

## ğŸ” Overview
RAG Document Assistant is a Retrieval-Augmented Generation (RAG) based application that allows users to upload PDFs or use text files, ask natural language questions, retrieve relevant context using vector search, and generate hallucination-safe answers.

The system supports both **local embeddings** (free, offline) and **OpenAI embeddings** (production-grade), making it suitable for real-world deployment and interviews.

---

## ğŸ§  What is RAG?
Retrieval-Augmented Generation (RAG) combines:
1. Information Retrieval (vector similarity search)
2. Text Generation (LLMs)

Instead of relying purely on an LLMâ€™s internal knowledge, RAG retrieves relevant document chunks and injects them into the prompt, producing grounded and factual answers.

---

## ğŸ—ï¸ System Architecture

PDF / Text  
â†’ Chunking  
â†’ Vector Embeddings (Local / OpenAI)  
â†’ FAISS Vector Database  
â†’ Top-K Retrieved Chunks  
â†’ LLM with Guardrails  
â†’ Final Answer / Refusal  

---

## âš™ï¸ Key Features

- ğŸ“„ PDF Upload & Text File Support  
- âœ‚ï¸ Intelligent Chunking with Overlap  
- ğŸ§® Local (HuggingFace) & OpenAI Embeddings  
- âš¡ FAISS Vector Search  
- ğŸ›¡ï¸ Strict Hallucination Guardrails  
- ğŸ” Modular, Model-Agnostic Design  

---

## ğŸ” Embedding Strategy

| Mode | Usage |
|---|---|
| Local (HuggingFace) | Development, testing, zero cost |
| OpenAI | Production, higher semantic accuracy |

Switching embedding backends requires no architectural change.

---

## ğŸ›¡ï¸ Hallucination-Safe Answering

If the answer is not present in the retrieved context, the system responds with:

> â€œThe document does not contain this information.â€

This prevents post-retrieval hallucinations and improves trustworthiness.

---

## ğŸ“¸ Screenshots (Visual Walkthrough)

> Add screenshots in a `screenshots/` folder and reference them below.  
> This section greatly improves recruiter and interviewer understanding.

### 1ï¸âƒ£ Application Home & Configuration
![App Home](screenshots/01_app_home.png)

Shows:
- Embedding backend selection (Local / OpenAI)
- LLM selection
- Data source selection (PDF / Text)

---

### 2ï¸âƒ£ PDF Upload & Chunk Processing
![PDF Upload](screenshots/02_pdf_upload.png)

Shows:
- PDF upload via UI
- Automatic text extraction
- Chunk count confirmation

---

### 3ï¸âƒ£ Semantic Retrieval (FAISS)
![Retrieval](screenshots/03_retrieval.png)

Shows:
- Top-K retrieved chunks
- Semantic (meaning-based) search
- Grounded context display

---

### 4ï¸âƒ£ Final Answer with Guardrails
![Final Answer](screenshots/04_final_answer.png)

Shows:
- Hallucination-safe answer
- Explicit refusal when answer is not in document

---

### 5ï¸âƒ£ Negative Test (No Hallucination)
![Negative Test](screenshots/05_negative_test.png)

Shows:
- Question not present in document
- Correct refusal instead of hallucination

---

## ğŸ§ª Evaluation Metrics (IMPORTANT)

This project is evaluated using **behavioral and retrieval-focused metrics**, not traditional accuracy alone.

### 1ï¸âƒ£ Retrieval Quality
- Top-K relevance check
- Manual inspection of retrieved chunks
- Ensures semantic correctness

### 2ï¸âƒ£ Grounded Answer Rate
- Percentage of answers strictly derived from retrieved context
- Target: High grounding, zero hallucination

### 3ï¸âƒ£ Refusal Accuracy (Negative Testing)
- System correctly refuses when data is missing
- Example: â€œWho invented RAG?â€

### 4ï¸âƒ£ Latency
- Embedding time
- Retrieval response time
- Answer generation time

### 5ï¸âƒ£ Cost Awareness
- Local embeddings for development
- OpenAI embeddings only for production

---

## ğŸ§ª How to Test

### Positive Test
```
What is Retrieval-Augmented Generation?
```

Expected: Correct, grounded answer.

### Negative Test
```
Who invented RAG?
```

Expected: Explicit refusal.

---

## ğŸ› ï¸ Tech Stack

- Python
- Streamlit
- LangChain
- FAISS
- Sentence-Transformers
- OpenAI (optional)
- PyPDF

---

## ğŸ“ Project Structure

RAG Document Assistant/
â”œâ”€â”€ app.py
â”œâ”€â”€ rag_test_data.txt
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ 01_app_home.png
â”‚   â”œâ”€â”€ 02_pdf_upload.png
â”‚   â”œâ”€â”€ 03_retrieval.png
â”‚   â”œâ”€â”€ 04_final_answer.png
â”‚   â””â”€â”€ 05_negative_test.png
â”œâ”€â”€ .env (optional)
â””â”€â”€ venv/

---

## â–¶ï¸ How to Run

```bash
source venv/bin/activate
pip install -r requirements.txt
python -m streamlit run app.py
```

---

## ğŸ¤ Interview-Ready Explanation

â€œI implemented a RAG pipeline using FAISS for semantic retrieval and added strict prompt guardrails to eliminate hallucinations. The system supports both local and OpenAI embeddings, enabling cost-efficient development and scalable production deployment.â€

---

## ğŸš€ Future Enhancements

- Source citations per answer
- Confidence scoring
- Multi-document ingestion
- Cloud deployment (AWS / GCP)
- Authentication & access control

---

## ğŸ Final Note

This project demonstrates real-world RAG engineering practices including modular design, hallucination control, evaluation-driven development, and production-ready thinking.
